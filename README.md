# **Bandit Tools**
This repository contains software packages and tools for multi-armed bandits and algorithms.

## **Tools**
[**Bernoulli Bandit Simulator**](bbsim):
Multi-threaded simulator for running Bernoulli bandit experiments. Accessible via Python API.

[**Optmal Policy for Bernoulli Bandits**](OptPol):
Multi-threaded optimal policy computation. Indexing provided. Accessible via Python API.

[**Whittle Index**](whittle):
Provides pre-computed Whittle Index table up to time horizon 300. Indices accessible via Python API.

[**UCBT_ob_0.73_0.19**](ucbT_ob_0.73_0.19):
Python implementation of UCBT_ob_0.73_0.19 algorithm. 

## **Requirements**
Currently, Python APIs require Boost.Python (libboost_python).